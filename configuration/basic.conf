[fullyconnected]
activation_fn = None
normalizer_fn = None
normalizer_params = None
weights_initializer = 'zeros'
weights_regularizer = None
biases_initializer = 'zeros'
biases_regularizer = None
reuse = None
variables_collections = None
outputs_collections = None
trainable = True
scope = None

[loss]
loss = 'cross_entropy'
dim = -1
name = None

[optimizer]
optimizer = 'GradientDescent'
use_locking = False
name = 'GradientDescent'

[accuracy]
accuracy = 'argmax'
axis = 1

[saver]
max_to_keep = 5
model_name = 'mnist_softmax'

[train]
batch_size = 256
init_learning_rate = 1.0
max_epoch = 100
expected_accuracy = 1.0
accuracy_every_epoch = 5
save_every_epoch = 5